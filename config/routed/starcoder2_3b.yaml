initialize_from_hf: "bigcode/starcoder2-3b"
full_ft: false
embedding_router_token_ft: false
data:
  train_urls:
    - gs://usc-stack-v2/20250122-flattened-shuffled/shard-{00..58}.jsonl.gz
  validation_urls:
    - gs://usc-stack-v2/20250122-flattened-shuffled/shard-{59..60}.jsonl.gz
  cache_dir: "gs://usc2-datacache/20250122-flattened-shuffled/starcoder"
  tokenizer: "bigcode/starcoder2-3b"
  shuffle: false
  predict_prefix: false
  predict_router_token: false
  predict_fim_token: false
  add_router_token: false
  pack: true
  data_format: "flattened"
  prefix_token: "<fim_prefix>"
  middle_token: "<fim_middle>"
  suffix_token: "<fim_suffix>"
  repo_name_token: "<repo_name>"
  file_sep_token: "<file_sep>"
  eos_token: "<|endoftext|>"
  pad_token: "<fim_pad>"
model:
  type: rstarcoder
  seq_len: 4096
  hidden_dim: 3072
  intermediate_dim: 12288
  num_heads: 24
  num_layers: 30
  num_kv_heads: 2
  layer_norm_epsilon: 1e-5
  rope:
    type: default
    theta: 999999.4420358813
  tie_word_embeddings: true

  activation_function: "gelu_new"
  use_flash_attention: true
  attn_backend: splash
  flash_attention_block_size: 512
  use_bias: true

  disable_expert_mask: false
  ident_expert_mask: false

  prefill_expert: true
  expert_type: "mlp"
  expert_init: "mlp_zero_down"
  expert_init_scale: 0.01

  num_experts: 32
  expert_rank: 128
  top_k: 4
  scale: 1.0

trainer:
  wandb:
    project: "levanter-seqmoe"
  mp: p=f32,c=bfloat16
  train_batch_size: 256
  per_device_parallelism: 4
  num_train_steps: 500
  steps_per_eval: 10
  max_eval_samples: 512
  per_device_eval_parallelism: 4
  tensor_parallel_axes: ["mlp", "heads"]
  fsdp_axis: "embed"
  batch_axis: "batch"
  checkpointer:
    base_path: gs://usc2-ckpt/starcoder2-3b-misc
    save_interval: 15m
  abort_if_loss_above: 8.0

optimizer:
  type: adam
  learning_rate: 6e-3
  weight_decay: 0.0
  warmup: 0.01

save_torch_state_path: gs://usc2-ckpt/starcoder2-3b-state-dicts
