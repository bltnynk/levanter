{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "is_eu4w = False\n",
    "eu4w_base_args = {\n",
    "    \"data.train_urls\": \"\\\"['gs://euw4-stack-v2/20250122-flattened-shuffled/shard-{00..58}.jsonl.gz']\\\"\",\n",
    "    \"data.validation_urls\": \"\\\"['gs://euw4-stack-v2/20250122-flattened-shuffled/shard-{59..60}.jsonl.gz']\\\"\",\n",
    "    \"data.cache_dir\": \"gs://euw4-datacache/20250122-flattened-shuffled\",\n",
    "    \"trainer.checkpointer.base_path\": \"gs://euw4-ckpt\",\n",
    "    \"trainer.per_device_parallelism\": 2,\n",
    "    \"trainer.per_device_eval_parallelism\": 2,\n",
    "    \"model.upcast_attn\": \"true\",\n",
    "}\n",
    "all_args = eu4w_base_args if is_eu4w else {}\n",
    "tpu_type = \"v3-8\" if is_eu4w else \"v4-8\"\n",
    "script = \"src/levanter/main/routed_lm.py\"\n",
    "\n",
    "def datetime_str():\n",
    "    return datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "def make_runs(out_file, sweep_name, sweep_params, extra_attrs, group, i=0, sort_key=None, commented=False):\n",
    "    callables = {k: v for k, v in sweep_params.items() if callable(v)}\n",
    "    sweep_params = {k: v for k, v in sweep_params.items() if not callable(v)}\n",
    "    ks, vs = zip(*sweep_params.items())\n",
    "    ks, vs = list(ks), list(vs)\n",
    "    out_file.write(f\"##### {group} #####\\n\")\n",
    "    sort_idx = 0 if sort_key is None else ks.index(sort_key)\n",
    "    all_v = sorted(list(product(*vs)), key=lambda x: x[sort_idx])\n",
    "    for v in all_v:\n",
    "        a = extra_attrs.copy()\n",
    "        for k, vv in zip(ks, v):\n",
    "            a[k] = vv\n",
    "        a[\"trainer.wandb.tags\"] = f\"'[{sweep_name}, {group}]'\"\n",
    "        a[\"trainer.wandb.name\"] = f\"{sweep_name}_{group}_{i}\"\n",
    "        cmd = f\"python {script} --config_path config/rlora.yaml\"\n",
    "        a.update({k: v(a) for k, v in callables.items()})\n",
    "        for k, v in a.items():\n",
    "            cmd += f\" --{k} {v}\"\n",
    "        if commented:\n",
    "            cmd = \"# \" + cmd\n",
    "        out_file.write(cmd + \"\\n\")\n",
    "        i += 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num pikachu runs 210\n",
      "python ./infra/launch_on_ray.py --tpu_type v4-8 /Users/will/proj/levanter/infra/sweeps/pikachu_2502071559.cmd\n"
     ]
    }
   ],
   "source": [
    "sweep_name = \"pikachu\"\n",
    "\n",
    "sweep_params = {\n",
    "    \"optimizer.learning_rate\": np.logspace(-2, -5, 6).round(6),\n",
    "    \"trainer.num_train_steps\": np.logspace(np.log10(50), np.log10(500), 4).round(-1).astype(int)\n",
    "}\n",
    "\n",
    "attrs = all_args | {\n",
    "    \"model.num_experts\": 32,\n",
    "    \"model.expert_rank\": 128,\n",
    "    \"model.top_k\": 4,\n",
    "    \"model.expert_type\": \"mlp_glu\",\n",
    "    \"model.expert_init\": \"mlp_zero_down\",\n",
    "    \"model.expert_init_scale\": 0.01,\n",
    "}\n",
    "\n",
    "baseline_attrs = attrs.copy()\n",
    "baseline_attrs[\"model.num_experts\"] = 1\n",
    "baseline_attrs[\"model.expert_rank\"] = attrs[\"model.expert_rank\"] * attrs[\"model.top_k\"]\n",
    "baseline_attrs[\"model.ident_expert_mask\"] = \"true\"\n",
    "baseline_attrs[\"model.top_k\"] = 1\n",
    "\n",
    "max_k_attrs = attrs.copy()\n",
    "max_k_attrs[\"model.top_k\"] = max_k_attrs[\"model.num_experts\"]\n",
    "\n",
    "max_k_prefill_exp_attrs = max_k_attrs | {\n",
    "    'model.prefill_expert': 'true'\n",
    "}\n",
    "\n",
    "prefill_exp_attrs = attrs | {\n",
    "    'model.prefill_expert': 'true'\n",
    "}\n",
    "\n",
    "sigmoid_prefill_exp_attrs = prefill_exp_attrs | {\n",
    "    'model.router_activation': 'sigmoid'\n",
    "}\n",
    "\n",
    "tight_lr_params = { \n",
    "    \"optimizer.learning_rate\": np.logspace(np.log10(1.58e-4), np.log10(1.5e-3), 10).round(6),\n",
    "    \"trainer.num_train_steps\": [500]\n",
    "}\n",
    "\n",
    "zloss_params = {\n",
    "    \"optimizer.learning_rate\": np.logspace(np.log10(5e-3), np.log10(6e-5), 6).round(6),\n",
    "    \"trainer.num_train_steps\": [110],\n",
    "    \"router_z_loss_weight\": np.logspace(-1, -5, 6).round(6),\n",
    "}\n",
    "zloss_attrs = prefill_exp_attrs | {\n",
    "    \"trainer.abort_if_loss_above\": 8.0,\n",
    "}\n",
    "\n",
    "\n",
    "os.makedirs(\"sweeps\", exist_ok=True)\n",
    "fname = os.path.abspath(f\"sweeps/{sweep_name}_{datetime_str()}.cmd\")\n",
    "with open(fname, \"w\") as f:\n",
    "    i = 0\n",
    "    i = make_runs(f, sweep_name, sweep_params, baseline_attrs, \"baseline\", i, sort_key=\"trainer.num_train_steps\", commented=True)\n",
    "    i = make_runs(f, sweep_name, sweep_params, attrs, \"seqmoe\", i, sort_key=\"trainer.num_train_steps\", commented=True)\n",
    "    i = make_runs(f, sweep_name, sweep_params, max_k_attrs, \"maxk\", i, sort_key=\"trainer.num_train_steps\", commented=True)\n",
    "    i = make_runs(f, sweep_name, sweep_params, max_k_prefill_exp_attrs, \"maxk_prefill_expert_v2\", i, sort_key=\"trainer.num_train_steps\", commented=True)\n",
    "    i = make_runs(f, sweep_name, sweep_params, prefill_exp_attrs, \"prefill_expert_v2\", i, sort_key=\"trainer.num_train_steps\", commented=True)\n",
    "    i = make_runs(f, sweep_name, sweep_params, sigmoid_prefill_exp_attrs, \"sigmoid_prefill_expert_v2\", i, sort_key=\"trainer.num_train_steps\", commented=True)\n",
    "    i = make_runs(f, sweep_name, tight_lr_params, prefill_exp_attrs, \"prefill_expert_v2_tightlr\", i, sort_key=\"optimizer.learning_rate\", commented=True)\n",
    "    i = make_runs(f, sweep_name, tight_lr_params, baseline_attrs, \"baseline_tightlr\", i, sort_key=\"optimizer.learning_rate\", commented=True)\n",
    "    i = make_runs(f, sweep_name, tight_lr_params, baseline_attrs, \"baseline_tightlr\", i, sort_key=\"optimizer.learning_rate\", commented=True)\n",
    "    i = make_runs(f, sweep_name, zloss_params, zloss_attrs, \"zloss\", i, sort_key=\"optimizer.learning_rate\", commented=False)\n",
    "    i\n",
    "print(\"Num pikachu runs\", i)\n",
    "print(f\"python ./infra/launch_on_ray.py --tpu_type {tpu_type} {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.num_experts': [8, 16, 64, 128, 256], 'optimizer.learning_rate': array([0.00043 , 0.000552, 0.000708, 0.00091 ]), 'trainer.per_device_parallelism': <function <lambda> at 0x1052ffba0>, 'trainer.per_device_eval_parallelism': <function <lambda> at 0x1052ff9c0>}\n",
      "Num bulba runs 80\n",
      "python ./infra/launch_on_ray.py --tpu_type v4-8 /Users/will/proj/levanter/infra/sweeps/bulba_2502071501.cmd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sweep_name = \"bulba\"\n",
    "\n",
    "sweep_params = {\n",
    "    \"optimizer.learning_rate\": np.logspace(np.log10(1.58e-4), np.log10(1.5e-3), 10).round(6),\n",
    "}\n",
    "\n",
    "attrs = all_args | {\n",
    "    \"model.num_experts\": 32,\n",
    "    \"model.expert_rank\": 128,\n",
    "    \"model.top_k\": 4,\n",
    "    \"model.expert_type\": \"mlp_glu\",\n",
    "    \"model.expert_init\": \"mlp_zero_down\",\n",
    "    \"model.expert_init_scale\": 0.01,\n",
    "    \"model.prefill_expert\": 'true',\n",
    "    \"trainer.num_train_steps\": 110,\n",
    "}\n",
    "\n",
    "baseline_attrs = attrs.copy()\n",
    "baseline_attrs[\"model.num_experts\"] = 1\n",
    "baseline_attrs[\"model.expert_rank\"] = attrs[\"model.expert_rank\"] * attrs[\"model.top_k\"]\n",
    "baseline_attrs[\"model.ident_expert_mask\"] = \"true\"\n",
    "baseline_attrs[\"model.top_k\"] = 1\n",
    "baseline_attrs[\"model.prefill_expert\"] = \"false\"\n",
    "\n",
    "sigmoid_attrs = attrs | {\n",
    "    'model.router_activation': 'sigmoid'\n",
    "}\n",
    "\n",
    "per_layer_attrs = attrs | {\n",
    "    \"model.route_each_layer\": \"true\"\n",
    "}\n",
    "\n",
    "more_experts_params = {\n",
    "    \"model.num_experts\": [8, 16, 64, 128, 256],\n",
    "    \"optimizer.learning_rate\": sweep_params[\"optimizer.learning_rate\"][4:-2],\n",
    "    \"trainer.per_device_parallelism\": lambda a: 4 if a[\"model.num_experts\"] < 128 else 1,\n",
    "    \"trainer.per_device_eval_parallelism\": lambda a: 4 if a[\"model.num_experts\"] < 128 else 1,\n",
    "}\n",
    "print(more_experts_params)\n",
    "\n",
    "total_memory = attrs[\"model.num_experts\"] * attrs[\"model.expert_rank\"]\n",
    "active_memory = attrs[\"model.top_k\"] * attrs[\"model.expert_rank\"]\n",
    "# E * r = M\n",
    "# k * r = A\n",
    "# Fix M, A, vary E, solve for r, k\n",
    "# r = M / E\n",
    "# k = A / r = A * E / M\n",
    "granularity_params = more_experts_params | {\n",
    "    \"model.num_experts\": [8, 16, 64, 128, 256],\n",
    "    \"model.expert_rank\": lambda a:  total_memory // a[\"model.num_experts\"],\n",
    "    \"model.top_k\": lambda a:  active_memory * a[\"model.num_experts\"] // total_memory\n",
    "}\n",
    "del granularity_params[\"trainer.per_device_eval_parallelism\"]\n",
    "del granularity_params[\"trainer.per_device_parallelism\"]\n",
    "\n",
    "\n",
    "os.makedirs(\"sweeps\", exist_ok=True)\n",
    "fname = os.path.abspath(f\"sweeps/{sweep_name}_{datetime_str()}.cmd\")\n",
    "with open(fname, \"w\") as f:\n",
    "    i = 0\n",
    "    i = make_runs(f, sweep_name, sweep_params, baseline_attrs, \"baseline\", i, commented=True)\n",
    "    i = make_runs(f, sweep_name, sweep_params, attrs, \"seqmoe\", i, commented=True)\n",
    "    i = make_runs(f, sweep_name, sweep_params, sigmoid_attrs, \"seqmoe_sigmoid\", i, commented=True)\n",
    "    i = make_runs(f, sweep_name, sweep_params, per_layer_attrs, \"seqmoe_perlayer\", i, commented=True)\n",
    "    i = make_runs(f, sweep_name, more_experts_params, attrs, \"seqmoe_expert_sweep\", i, commented=False)\n",
    "    i = make_runs(f, sweep_name, granularity_params, attrs, \"seqmoe_granularity\", i, commented=False)\n",
    "    i\n",
    "print(f\"Num {sweep_name} runs\", i)\n",
    "print(f\"python ./infra/launch_on_ray.py --tpu_type {tpu_type} {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num charmander runs 72\n",
      "python ./infra/launch_on_ray.py --tpu_type v4-8 /Users/will/proj/levanter/infra/sweeps/charmander_2502071501.cmd\n"
     ]
    }
   ],
   "source": [
    "sweep_name = \"charmander\"\n",
    "lrs = np.logspace(np.log10(1.5e-3), -6, 6).round(6)\n",
    "sweep_params = {\n",
    "    \"optimizer.learning_rate\": lrs,\n",
    "    \"full_ft_base_weights_optimizer.learning_rate\": lrs,\n",
    "}\n",
    "\n",
    "attrs = all_args | {\n",
    "    \"model.num_experts\": 32,\n",
    "    \"model.expert_rank\": 128,\n",
    "    \"model.top_k\": 4,\n",
    "    \"model.expert_type\": \"mlp_glu\",\n",
    "    \"model.expert_init\": \"mlp_zero_down\",\n",
    "    \"model.expert_init_scale\": 0.01,\n",
    "    \"optimizer.warmup\": 0.08,\n",
    "    \"full_ft_base_weights_optimizer\": \"\\\"{'type': 'adam'}\\\"\",\n",
    "    \"full_ft_base_weights_optimizer.weight_decay\": 0.0,\n",
    "    \"full_ft_base_weights_optimizer.warmup\": 0.08,\n",
    "    \"trainer.num_train_steps\": 50,\n",
    "    \"full_ft\": \"true\",\n",
    "}\n",
    "\n",
    "baseline_attrs = attrs.copy()\n",
    "baseline_attrs[\"model.num_experts\"] = 1\n",
    "baseline_attrs[\"model.expert_rank\"] = attrs[\"model.expert_rank\"] * attrs[\"model.top_k\"]\n",
    "baseline_attrs[\"model.ident_expert_mask\"] = \"true\"\n",
    "baseline_attrs[\"model.top_k\"] = 1\n",
    "baseline_attrs[\"model.prefill_expert\"] = \"false\"\n",
    "\n",
    "os.makedirs(\"sweeps\", exist_ok=True)\n",
    "fname = os.path.abspath(f\"sweeps/{sweep_name}_{datetime_str()}.cmd\")\n",
    "with open(fname, \"w\") as f:\n",
    "    i = 0\n",
    "    i = make_runs(f, sweep_name, sweep_params, baseline_attrs, \"baseline\", i)\n",
    "    i = make_runs(f, sweep_name, sweep_params, attrs, \"seqmoe\", i)\n",
    "print(f\"Num {sweep_name} runs\", i)\n",
    "print(f\"python ./infra/launch_on_ray.py --tpu_type {tpu_type} {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
